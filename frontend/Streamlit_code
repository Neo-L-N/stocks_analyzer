
import pandas as pd
import streamlit as st
import plotly.express as px

st.set_page_config(layout='wide')
# Inject custom CSS for centering
st.markdown("""
    <style>
    .centered-title {
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

# Use the custom CSS class for the title
st.markdown("<h1 class='centered-title'>Stock Price Analyzer with Machine Learning</h1>", unsafe_allow_html=True)

st.image('media/stocks.jpeg', use_column_width=True)

st.header('\n\nMachine Learning Models for Stock Price Prediction')

st.write('This project aims to predict stock prices using historical '
         'data of S&P 500 stocks. Utilizing multiple machine learning models including'
         ' Support Vector Regression (SVR), Random Forest (RF), \nLong Short-Term Memory (LSTM), '
         'LightGBM, CatBoost, and XGBoost are trained and evaluated based on their performance.\n')

st.subheader('Train and Test Split\n')
st.markdown('   * __Training Set__ : Initially 80% of the data, further reduced to 500 samples for quicker training.\n'
            ' * __Testing Set__ : 20% of the data.'
            '\n\nThis means that the models are trained on a small, randomly sampled subset of the original dataset '
            '(500 samples), and are evaluated on 20% of the original dataset. This sampling is done to speed up the '
            'training process, \nbut it might affect the model''s performance depending on the dataset size and '
            'characteristics.\n\n')

st.subheader('Choose a model to see how it works')
model = st.selectbox('',
                     options=['Choose a Model', 'Support Vector Regression (SVR)', 'Random Forest (RF)',
                              'Long Short-Term Memory (LSTM)',
                              'Light Gradient-Boosting Machine (LightGBM)', 'CatBoost', 'XGBoost'])

if model == 'Support Vector Regression (SVR)':

    st.markdown("Support Vector Regression (SVR) is a tool used to make predictions, especially when the relationship "
                "between variables isn't straightforward. It works by finding a line (or curve) that best "
                "fits the data while keeping errors as small as possible\n"
                "Here is how SVR works:\n\n"
                "*  It uses a mathematical method called a kernel function to transform the data into higher-"
                "dimensional space, making it easier to spot patterns, even if they're not obvious in the original "
                "data"
                "\n*    It sets a ""margin of tolerance"", where small errors are acceptable, si it focuses on the "
                "bigger picture rather than overreacting to every little variation"
                "\n\n SVR is helpful for tasks where the data might have complex relationships, and it can be adjusted "
                "using settings like the type of kernel (linear or non-linear) and how much flexibility to allow in "
                "fitting the data.")

    col1, col2, col3 = st.columns(3)
    with col2:
        st.video('media/svm.mp4')


elif model == 'Random Forest (RF)':

    st.markdown("Random Forest is a prediction tool that works by creating a ""forest"
                "of decision trees and combining their results. Each tree is like an independent expert making its "
                "own prediction, and the forest combines all these opinions for a more reliable result."
                "Here’s how Random Forest works:\n\n"
                "*  Each tree looks at a different random portion of the data, which helps it focus on unique aspects "
                "of the problem."
                "\n*    At each step of building a tree, it picks a random subset of features to decide how to "
                "split the data."
                "\n\n By combining all the trees:"
                "\n*    For tasks like predicting numbers (regression), it averages their results."
                "\n*    For tasks like deciding categories (classification), it goes with the majority vote."
                "\n\nThis randomness helps Random Forest avoid overfitting (where a model memorizes the data too "
                "much and struggles with new data) and ensures more accurate and stable predictions.")

    col1, col2, col3 = st.columns(3)
    with col2:
        st.video('media/random_forest.mp4')


elif model == 'Long Short-Term Memory (LSTM)':
    st.markdown("Long Short-Term Memory (LSTM) is a type of advanced computer model that helps us understand patterns "
                "over time. Think of it as a really smart memory system that can remember important information from "
                "the past while deciding what details to forget. This makes it especially useful for tasks where the "
                "order of events matters, like predicting stock prices, where yesterday's prices affect today's."
                "Here's how it works:"
                "\n\nLSTM is made up of ""cells,"" which are like tiny decision-makers."
                "\n\nEach cell has three ""gates"" (like doors) that decide:\n\n"
                "\n*  What new information to let in."
                "\n*  What old information to forget.\n"
                "\n*    What information to pass on to the next step."
                "\n\nThis design allows LSTM to focus on the important parts of a sequence and ignore the unimportant ones. Unlike older "
                "models, it doesn’t lose track of details from the distant past, which is a big advantage for understanding "
                "long-term trends.")

    col1, col2, col3 = st.columns(3)
    with col2:
        st.video('media/lstm.mp4')


elif model == 'Light Gradient-Boosting Machine (LightGBM)':
    st.markdown("LightGBM is a tool used to make accurate predictions quickly and efficiently. Think of it as a powerful"
                " problem-solver designed to handle large and complex datasets. It uses a technique called gradient"
                " boosting, which builds smarter decision trees to improve accuracy with each step."
                "What makes LightGBM special is how it works faster and uses less memory:"
                "\n*  It organizes data in a way that speeds up learning (called histogram-based learning)."
                "\n*  It grows decision trees in a unique way that focuses on the most important parts of the data.\n"
                "\n*  It bundles similar features together to save time and resources."
                "\n\nLightGBM is great for solving problems where there’s a lot of data and many details to consider."
                " It can be fine-tuned by adjusting settings like how many trees to build, how fast it learns, "
                "and what kind of problem it’s solving.")

    st.image('media/lgbm.png', width=800)

elif model == 'CatBoost':
    st.markdown("CatBoost is a tool made for predictions, especially when working with data that includes categories like "
                'Yes/No'" or "'Red/Blue/Green.'" It’s designed to handle this kind of data easily without much preparation."
                " What makes CatBoost stand out:"
                "\n*  It uses a clever method called ordered boosting to avoid mistakes like overfitting "
                "(where a model learns too much from past data and struggles to work with new data)."
                "\n*  It has special ways of working with categories that improve accuracy, such as assigning smart numerical values to categories.\n"
                "\n\nCatBoost is known for being easy to use, fast to train, and very accurate. You can adjust settings" 
                "like the number of steps it takes to improve, how quickly it learns, and how deep its decision trees go "
                "to tailor it to your needs.")

    st.image('media/catboost.png', width=800)

elif model == 'XGBoost':
    st.markdown(
        "XGBoost is like an upgraded version of traditional tools for making predictions. It’s designed to work "
        "efficiently and handle big tasks without slowing down."
        "Why XGBoost is so powerful:"
        "\n*  t uses techniques to avoid overfitting, which helps it make better predictions on new data."
        "\n*  It can run calculations in parallel, meaning it works much faster.\n"
        "\n*  It’s smart about handling missing or sparse data, so it doesn’t waste time on irrelevant details.\n"
        "\n\nXGBoost is flexible and can be adjusted for different types of problems by tweaking settings "
        "like how many rounds of improvement it goes through, how fast it learns, how complex the trees are, "
        "and what kind of goal it’s trying to achieve.")

    st.image('media/xgboost.png', width=800)

st.header('\nStock Selection and Predictions')

st.markdown('In this section, we will concentrate on the predictions made by two of the best-performing models: '
        'Support Vector Regression (SVR) and Random Forest. '
        'These models were selected based on their '
        'superior accuracy\nand performance in predicting stock prices, as evaluated through various performance metrics'
        '\n\n__Why SVR and Random Forest?__\n\n'
        '   * Support Vector Regression (SVR): SVR is known for its ability to handle high-dimensional '
        'data and find an optimal hyperplane that best fits the data points while minimizing the '
        'margin of error.\nIts robust nature and generalization ability make it an excellent choice '
        'for regression tasks such as stock price prediction.\n\n'
        '   * Random Forest: Random Forest is a powerful ensemble learning method that builds multiple decision '
        'trees and combines their outputs to improve accuracy and reduce overfitting.\nIts strength lies in its '
        'ability to capture complex patterns in data, making it highly effective for predicting future stock prices.')

# Load data
@st.cache_data
def load_data():
    return pd.read_csv('csv/processed_data_with_predictions.csv')


data = load_data()

# Model and Stock Selection
st.subheader('Stock Price Predictions Per Model')
model_choice = st.radio('Choose a Model to see Predictions',
                        options=['Support Vector Regression (SVR)', 'Random Forest'])
stock_choice = st.selectbox('Choose a Stock', data['Name'].unique())

# Filter data based on selections
model_column = 'svr_predicted' if model_choice == 'Support Vector Regression (SVR)' else 'rf_predicted'
filtered_data = data[data['Name'] == stock_choice]

# Plotting
st.subheader(f'{model_choice} Predictions vs Actual Closing Prices for {stock_choice}')
fig = px.line(filtered_data, x='date', y=['close', model_column],
              labels={'value': 'Stock Price', 'date': 'Date'},
              title=f'{stock_choice} Actual vs Predicted Closing Price ({model_choice})')

fig.update_layout(legend_title_text='Price Type', width=2000, height=700)
fig.update_traces(mode="lines")

st.plotly_chart(fig)
